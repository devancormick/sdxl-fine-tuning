# Inference Configuration

# Model paths
model:
  base_model: "./models/base_models/stable-diffusion-xl-base-1.0"
  lora_weights: "./models/lora_checkpoints/checkpoint-2000"
  controlnet_model: "./models/controlnet-openpose-sdxl-1.0"
  vae_model: "./models/vae/sdxl-vae-fp16-fix"

# Generation settings
generation:
  width: 1024
  height: 1024
  num_inference_steps: 20  # Reduced for 5-8s generation time (was 30)
  guidance_scale: 7.5
  controlnet_conditioning_scale: 1.0
  negative_prompt: "blurry, low quality, distorted, bad anatomy"
  
# Fast generation mode (5-8 seconds target)
fast_mode:
  num_inference_steps: 15  # Fast mode: 15 steps
  guidance_scale: 7.0
  use_torch_compile: true
  
# Performance optimization
optimization:
  use_xformers: true
  use_torch_compile: false  # Can enable for faster inference if PyTorch 2.0+
  enable_attention_slicing: true
  enable_vae_slicing: true
  enable_vae_tiling: false
  enable_cpu_offload: false  # Set to true if GPU memory is limited
  
# Device
device: "cuda"  # or "cpu"

